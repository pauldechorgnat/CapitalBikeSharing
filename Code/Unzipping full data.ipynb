{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import tqdm\n",
    "import zipfile\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "unzip_files = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"C:/Users/Marie/Desktop/Bike Sharing/Full Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compressed_files = listdir(path + 'Compressed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if unzip_files:    \n",
    "    for file in tqdm.tqdm(compressed_files):\n",
    "        zip_file = zipfile.ZipFile(path + 'Compressed/' + file, 'r')\n",
    "        zip_file.extractall(path)\n",
    "        zip_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_files = listdir(path)\n",
    "full_files = [f for f in full_files if f[-3:] == 'csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:44<00:00,  1.71s/it]\n"
     ]
    }
   ],
   "source": [
    "full_data = {}\n",
    "\n",
    "cleaning_all = False\n",
    "\n",
    "for f in tqdm.tqdm(full_files):\n",
    "    if f[-3:] == 'csv':\n",
    "        df_temp = pd.read_csv(path+f)\n",
    "        # df_temp = df_temp.dropna()\n",
    "        df_temp = df_temp.drop(df_temp.columns[0], axis = 1)\n",
    "        cols = list(df_temp.columns)\n",
    "        cols[0] = 'StartDate'\n",
    "        cols[-1] = 'MemberType'\n",
    "        cols[-2] = 'BikeNumber'\n",
    "        \n",
    "        cols = [str(col).lower().replace(' ', '') for col in cols]\n",
    "        \n",
    "        df_temp.columns = cols\n",
    "        if cleaning_all == True:\n",
    "            if len(cols) == 6:\n",
    "                df_temp['endstationnumber'] = df_temp['endstation'].apply(lambda x: str(x).split(' (')[-1][:-1])\n",
    "                #df_temp = df_temp[df_temp.endstationnumber.apply(lambda x: len(str(x)))==5]\n",
    "                df_temp['endstation'] = df_temp['endstation'].apply(lambda x: str(x).split(' (')[0])\n",
    "\n",
    "                df_temp['startstationnumber'] = df_temp['startstation'].apply(lambda x: str(x).split(' (')[-1][:-1])\n",
    "                #df_temp = df_temp[df_temp.startstationnumber.apply(lambda x: len(str(x)))==5]\n",
    "                df_temp['startstation'] = df_temp['startstation'].apply(lambda x: str(x).split(' (')[0])\n",
    "        else :\n",
    "            df_temp = df_temp[['startdate', 'membertype']]\n",
    "            \n",
    "            \n",
    "        df_temp['casual'] = df_temp['membertype'].apply(lambda x: str(x).lower()=='casual')*1\n",
    "        df_temp['registered'] = 1- df_temp['casual']\n",
    "        df_temp['cnt'] = 1\n",
    "        df_temp = df_temp.drop('membertype', axis =1)\n",
    "        \n",
    "        \n",
    "        full_data[f] = {\n",
    "            'data':df_temp,\n",
    "            'size':df_temp.shape,\n",
    "            'columns':df_temp.columns,\n",
    "            'types':df_temp.dtypes\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [04:46<00:00, 11.93s/it]\n"
     ]
    }
   ],
   "source": [
    "key = list(full_data.keys())[0]\n",
    "\n",
    "df_daily = full_data[key]['data']\n",
    "\n",
    "df_daily['startdate'] = pd.to_datetime(df_daily['startdate'])\n",
    "df_daily['year'] = df_daily['startdate'].apply(lambda x: x.year)\n",
    "df_daily['month'] = df_daily['startdate'].apply(lambda x: x.month)\n",
    "df_daily['day'] = df_daily['startdate'].apply(lambda x: x.day)\n",
    "df_daily['wkday'] = df_daily['startdate'].apply(lambda x: x.weekday())\n",
    "df_daily['hour'] = df_daily['startdate'].apply(lambda x: x.hour)\n",
    "df_daily = df_daily.drop('startdate', axis = 1) \n",
    "\n",
    "df_daily = df_daily.groupby(['year', 'month', 'day', 'wkday', 'hour']).sum()\n",
    "\n",
    "for key in tqdm.tqdm(list(full_data.keys())[1:]):\n",
    "    \n",
    "    df_by_day = full_data[key]['data']\n",
    "\n",
    "    df_by_day['startdate'] = pd.to_datetime(df_by_day['startdate'])\n",
    "    df_by_day['year'] = df_by_day['startdate'].apply(lambda x: x.year)\n",
    "    df_by_day['month'] = df_by_day['startdate'].apply(lambda x: x.month)\n",
    "    df_by_day['day'] = df_by_day['startdate'].apply(lambda x: x.day)\n",
    "    df_by_day['wkday'] = df_by_day['startdate'].apply(lambda x: x.weekday())\n",
    "    df_by_day['hour'] = df_by_day['startdate'].apply(lambda x: x.hour)\n",
    "    df_by_day = df_by_day.drop('startdate', axis = 1)\n",
    "    \n",
    "    df_daily = pd.concat([df_daily, df_by_day.groupby(['year', 'month', 'day', 'wkday', 'hour']).sum()], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_daily.reset_index().to_csv(path + 'Cleaned Data/full_hourly_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = list(full_data.keys())[0]\n",
    "\n",
    "df_end_station = full_data[key]['data'][['endstation', 'endstationnumber']].drop_duplicates()\n",
    "\n",
    "for key in list(full_data.keys())[1:]:\n",
    "    df_end_station = pd.concat([df_end_station, full_data[key]['data'][['endstation', 'endstationnumber']].drop_duplicates()], axis = 0)\n",
    "    \n",
    "df_end_station['temp'] = df_end_station['endstation'].apply(lambda x: str(x).split(' (')[-1][:-1])\n",
    "df_end_station['endstation'] = df_end_station['endstation'].apply(lambda x: str(x).split(' (')[0])\n",
    "\n",
    "df_end_station['endstationnumber'][df_end_station['endstationnumber']==0] = df_end_station['temp'][df_end_station['endstationnumber']==0]\n",
    "\n",
    "df_end_station = df_end_station.drop('temp', axis = 1).drop_duplicates()\n",
    "\n",
    "print(len(pd.unique(df_end_station.endstationnumber)))\n",
    "\n",
    "df_end_station.columns = ['station', 'stationNumber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = list(full_data.keys())[0]\n",
    "\n",
    "df_start_station = full_data[key]['data'][['startstation', 'startstationnumber']].drop_duplicates()\n",
    "\n",
    "for key in list(full_data.keys())[1:]:\n",
    "    df_start_station = pd.concat([df_start_station, full_data[key]['data'][['startstation', 'startstationnumber']].drop_duplicates()], axis = 0)\n",
    "    \n",
    "df_start_station['temp'] = df_start_station['startstation'].apply(lambda x: str(x).split(' (')[-1][:-1])\n",
    "df_start_station['startstation'] = df_start_station['startstation'].apply(lambda x: str(x).split(' (')[0])\n",
    "\n",
    "df_start_station['startstationnumber'][df_start_station['startstationnumber']==0] = df_start_station['temp'][df_start_station['startstationnumber']==0]\n",
    "\n",
    "df_start_station = df_start_station.drop('temp', axis = 1).drop_duplicates()\n",
    "\n",
    "print(len(pd.unique(df_start_station.startstationnumber)))\n",
    "\n",
    "df_start_station.columns = ['station', 'stationNumber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_stations = pd.concat([df_start_station, df_end_station], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_stations = df_stations.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_data[key]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_stations = df_stations[(df_stations.stationNumber.apply(lambda x: len(str(x))))==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_stations.stationNumber = df_stations.stationNumber.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_stations.to_csv(path + 'Cleaned Data/stations.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14403639\n"
     ]
    }
   ],
   "source": [
    "s = 0 \n",
    "for key in full_data.keys():\n",
    "    s +=full_data[key]['size'][0]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
