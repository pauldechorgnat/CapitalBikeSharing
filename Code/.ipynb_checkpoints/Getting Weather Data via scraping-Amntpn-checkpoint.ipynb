{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "from os import listdir\n",
    "from tqdm import tqdm as progression_bar\n",
    "import timeit\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['full_daily_data.csv', 'Weather Data']\n"
     ]
    }
   ],
   "source": [
    "path = 'C:/Users/Marie/Desktop/MSc DSBA/1. Big Data Analytics/1. Project/DummyFolder/'\n",
    "print(listdir(path))\n",
    "\n",
    "\n",
    "dates = [pd.to_datetime('2012/07/01') + datetime.timedelta(days = i) for i in range(1700)]\n",
    "dates = [str(d) for d in dates]\n",
    "dates = [d[:4]+'/'+d[5:7]+'/'+d[8:10] for d in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "url_base = 'http://www.historique-meteo.net/europe/france/paris/'\n",
    "\n",
    "with open(path + 'log_month.txt', 'w') as file:\n",
    "    file.write('LOG FILE : Scraping Weather Data \\n')\n",
    "    file.write(url_base + '\\n\\n')\n",
    "\n",
    "# List of tables\n",
    "tables = []\n",
    "month = dates[0][5:7]\n",
    "\n",
    "start = timeit.default_timer()\n",
    "for index, date in enumerate(dates):\n",
    "    \n",
    "    # Open url for the date\n",
    "    r = requests.get(url_base + date + '/')\n",
    "    \n",
    "    # Write status code in the log file\n",
    "    with open(path + 'log_month.txt', 'a') as file:\n",
    "        file.write('Date : {} || Status : {}\\n'.format(date, r.status_code))\n",
    "    \n",
    "    # Checking the status code : 200 is ok\n",
    "    if r.status_code == 200:\n",
    "        # Getting the data into the right shape for the building of the dataframe\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        table = soup.find_all(\"table\")[0]\n",
    "        table = table.contents[3]\n",
    "        \n",
    "        # Making the web data into a dataframe\n",
    "        new_table = pd.DataFrame(columns=range(0,6), index = range(0,14)) \n",
    "\n",
    "        row_marker = 0\n",
    "        for row in table.find_all('tr')[:-1]:\n",
    "            column_marker = 0\n",
    "            columns = row.find_all('td')\n",
    "            for column in columns:\n",
    "                new_table.iat[row_marker,column_marker] = column.get_text()\n",
    "                column_marker += 1\n",
    "            row_marker +=1\n",
    "        # Reshaping the dataframe\n",
    "        new_table = new_table.iloc[:,[0,3]]   \n",
    "        new_table.columns = ['field', date]\n",
    "        \n",
    "        \n",
    "    if month != date[5:7]:\n",
    "        df = tables[0]\n",
    "        try :\n",
    "            for t in tables[1:]:\n",
    "                df = df.merge(t, how = 'outer', on = 'field')\n",
    "                df.to_csv(path + 'Weather Data/weather_data_'+month+ '_'+ date[:4]+'.csv', index = False)\n",
    "            with open(path + 'log_month.txt', 'a') as file:\n",
    "                file.write('Managed to write back up file\\n')\n",
    "        except ValueError as e: \n",
    "            with open(path + 'log_month.txt', 'a') as file:\n",
    "                file.write('Did not write back up file !!\\n')\n",
    "                file.write(str(e)+'\\n')\n",
    "        month = date[5:7]\n",
    "        tables = [new_table]\n",
    "    else : \n",
    "        tables.append(new_table)\n",
    "        \n",
    "        \n",
    "file.close()\n",
    "end = timeit.default_timer()\n",
    "with open(path + 'log_month.txt', 'a') as file:\n",
    "    file.write('Execution Time : '+ str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dates=='2015/11/12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.historique-meteo.net/europe/france/paris/2012/07/01\n"
     ]
    }
   ],
   "source": [
    "print(url_base+ dates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
